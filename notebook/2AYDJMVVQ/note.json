{
  "paragraphs": [
    {
      "text": "%dep \nz.reset()\nz.load(\"joda-time:joda-time:2.8.2\")\nz.load(\"org.joda:joda-convert:1.7\")",
      "user": "anonymous",
      "dateUpdated": "Sep 8, 2017 1:34:10 PM",
      "config": {
        "colWidth": 12.0,
        "tableHide": false,
        "editorHide": false,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "Must be used before SparkInterpreter (%spark) initialized\nHint: put this paragraph before any Spark code and restart Zeppelin/Interpreter"
          }
        ]
      },
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "Must be used before SparkInterpreter (%spark) initialized"
      },
      "apps": [],
      "jobName": "paragraph_1439827242454_1171805612",
      "id": "20150817-160042_309573164",
      "dateCreated": "Aug 17, 2015 4:00:42 PM",
      "dateStarted": "Sep 8, 2017 1:34:10 PM",
      "dateFinished": "Sep 8, 2017 1:34:10 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md # Analyzing Access Logs\nCheck my original blog post: [Vagrant + Spark + Zeppelin a Toolbox to the Data Analyst](/2015/08/23/vagrant-spark-zeppelin-a-toolbox-to-the-data-analyst/)",
      "user": "anonymous",
      "dateUpdated": "Sep 8, 2017 1:34:10 PM",
      "config": {
        "colWidth": 12.0,
        "tableHide": false,
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "editorSetting": {}
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eAnalyzing Access Logs\u003c/h1\u003e\n\u003cp\u003eCheck my original blog post: \u003ca href\u003d\"/2015/08/23/vagrant-spark-zeppelin-a-toolbox-to-the-data-analyst/\"\u003eVagrant + Spark + Zeppelin a Toolbox to the Data Analyst\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch1\u003eAnalyzing Access Logs\u003c/h1\u003e\n\u003cp\u003eCheck my original blog post: \u003ca href\u003d\"/2015/08/23/vagrant-spark-zeppelin-a-toolbox-to-the-data-analyst/\"\u003eVagrant + Spark + Zeppelin a Toolbox to the Data Analyst\u003c/a\u003e\u003c/p\u003e\n"
      },
      "apps": [],
      "jobName": "paragraph_1439827160116_269863890",
      "id": "20150817-155920_280220446",
      "dateCreated": "Aug 17, 2015 3:59:20 PM",
      "dateStarted": "Sep 8, 2017 1:34:10 PM",
      "dateFinished": "Sep 8, 2017 1:34:10 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import java.net.URI\n\nimport org.joda.time.DateTime\nimport org.joda.time.format.DateTimeFormat\n\n// Case class to keep each record and their fields name/type \n  case class AccessLog(remoteIP: String, datetime: org.joda.time.DateTime, method: String, url: java.net.URI,\n    responseCode: String, size: Long, httpReferer: java.net.URI, agent: String)\n\n// Simple REGEX parser to extract fields from AccessLog file\n  def parseLog(line: String) \u003d {\n    def convertToDate(dateAsString: String): DateTime \u003d {\n      // 02/Jan/2003:02:06:41 -0700\n      val dtf \u003d DateTimeFormat.forPattern(\"dd/MMM/yyyy:HH:mm:ss Z\")\n      dtf.parseDateTime(dateAsString)\n    }\n\n    import scala.util.matching.Regex\n\n    val pattern \u003d new Regex( \"\"\"^([0-9\\.]+) - - \\[(.*?)\\] \"(.*?) (.*?) HTTP\\/.*?\" ([0-9]+) ([0-9]+) \"(.*?)\" \"(.*?)\"$\"\"\",\n      \"remoteIP\", \"datetime\", \"method\", \"url\", \"responseCode\", \"size\", \"httpReferer\", \"agent\")\n\n    val result \u003d pattern.findFirstMatchIn(line)\n\n    // if there is no match, return no record\n    if (result.isEmpty)\n      None\n\n    else {\n      try {\n        val m \u003d result.get\n\n        Some(\n          AccessLog(\n            remoteIP \u003d m.group(\"remoteIP\"),\n            datetime \u003d convertToDate(m.group(\"datetime\")),\n            method \u003d m.group(\"method\"),\n            url \u003d new URI(m.group(\"url\")),\n            responseCode \u003d m.group(\"responseCode\"),\n            size \u003d m.group(\"size\").toLong,\n            httpReferer \u003d new URI(m.group(\"httpReferer\")),\n            agent \u003d m.group(\"agent\")\n          )\n        )\n\n      } catch {\n          \n        // If something goes wrong, just return no record\n        // on a production env you should log and check the level of\n        // errors with Accumulators\n        // http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.Accumulator\n        case e: Exception \u003d\u003e None\n      }\n    }\n  }",
      "user": "anonymous",
      "dateUpdated": "Sep 8, 2017 1:34:10 PM",
      "config": {
        "colWidth": 12.0,
        "tableHide": false,
        "editorHide": false,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nimport java.net.URI\n\nimport org.joda.time.DateTime\n\nimport org.joda.time.format.DateTimeFormat\n\ndefined class AccessLog\n\nparseLog: (line: String)Option[AccessLog]\n"
          }
        ]
      },
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import java.net.URI\nimport org.joda.time.DateTime\nimport org.joda.time.format.DateTimeFormat\ndefined class AccessLog\nparseLog: (line: String)Option[AccessLog]\n"
      },
      "apps": [],
      "jobName": "paragraph_1439828032096_271223929",
      "id": "20150817-161352_2096077564",
      "dateCreated": "Aug 17, 2015 4:13:52 PM",
      "dateStarted": "Sep 8, 2017 1:34:10 PM",
      "dateFinished": "Sep 8, 2017 1:34:13 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// read all files from the filesystem\n// could be HDFS or S3 as well\nval logs \u003d sc.textFile(\"/opt/dataset/*.log.gz\")\n\n// Map each line (String) and parse with our function\nval logRecords \u003d logs.map(parseLog).\nflatMap(e \u003d\u003e e). // Use flatMap to remove empty records (None)\ncache // Cache this RDD as it will be used several times\n\n",
      "user": "anonymous",
      "dateUpdated": "Sep 8, 2017 1:34:10 PM",
      "config": {
        "colWidth": 12.0,
        "tableHide": false,
        "editorHide": false,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nlogs: org.apache.spark.rdd.RDD[String] \u003d /opt/dataset/*.log.gz MapPartitionsRDD[47] at textFile at \u003cconsole\u003e:38\n\nlogRecords: org.apache.spark.rdd.RDD[AccessLog] \u003d MapPartitionsRDD[49] at flatMap at \u003cconsole\u003e:45\n"
          }
        ]
      },
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "logs: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[1] at textFile at \u003cconsole\u003e:28\nlogRecords: org.apache.spark.rdd.RDD[AccessLog] \u003d MapPartitionsRDD[3] at flatMap at \u003cconsole\u003e:35\n"
      },
      "apps": [],
      "jobName": "paragraph_1439841526633_2077062511",
      "id": "20150817-195846_1569515141",
      "dateCreated": "Aug 17, 2015 7:58:46 PM",
      "dateStarted": "Sep 8, 2017 1:34:10 PM",
      "dateFinished": "Sep 8, 2017 1:34:15 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Another case class to access the fields, and convert to DataFrame\ncase class Record(remoteIP:String, datetime:Long, url:String, userAgent:String)\n\n// Create the new Record and convert to DataFrames\nval logRecodsDF \u003d logRecords.map( r\u003d\u003e Record(r.remoteIP, r.datetime.getMillis/1000, r.url.toString, r.agent.split(\" \")(0)) ).toDF\n\n// Register the DF as TempTable so you can run SQL Queries\nlogRecodsDF.registerTempTable(\"logs\")",
      "user": "anonymous",
      "dateUpdated": "Sep 8, 2017 1:34:10 PM",
      "config": {
        "colWidth": 12.0,
        "tableHide": false,
        "editorHide": false,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\ndefined class Record\n\nlogRecodsDF: org.apache.spark.sql.DataFrame \u003d [remoteIP: string, datetime: bigint ... 2 more fields]\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"
          }
        ]
      },
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "defined class Record\nlogRecodsDF: org.apache.spark.sql.DataFrame \u003d [remoteIP: string, datetime: bigint, url: string, userAgent: string]\n"
      },
      "apps": [],
      "jobName": "paragraph_1439841924063_1255930616",
      "id": "20150817-200524_50575152",
      "dateCreated": "Aug 17, 2015 8:05:24 PM",
      "dateStarted": "Sep 8, 2017 1:34:13 PM",
      "dateFinished": "Sep 8, 2017 1:34:18 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md ## Page-views by day",
      "user": "anonymous",
      "dateUpdated": "Sep 8, 2017 1:34:11 PM",
      "config": {
        "colWidth": 12.0,
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "editorSetting": {}
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003ePage-views by day\u003c/h2\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003ePage-views by day\u003c/h2\u003e\n"
      },
      "apps": [],
      "jobName": "paragraph_1440376103756_-565435386",
      "id": "20150824-002823_1972266022",
      "dateCreated": "Aug 24, 2015 12:28:23 AM",
      "dateStarted": "Sep 8, 2017 1:34:11 PM",
      "dateFinished": "Sep 8, 2017 1:34:11 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql SELECT from_unixtime(datetime, \u0027yyyy-MM-dd\u0027) AS dt, COUNT(*) as count \nFROM logs\nWHERE datetime \u003e\u003d 1049932800 -- 2003-04-10\nGROUP BY from_unixtime(datetime, \u0027yyyy-MM-dd\u0027)\nORDER BY dt\n",
      "user": "anonymous",
      "dateUpdated": "Sep 8, 2017 1:34:11 PM",
      "config": {
        "colWidth": 12.0,
        "tableHide": false,
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "lineChart",
              "height": 300.0,
              "optionOpen": false,
              "keys": [
                {
                  "name": "dt",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "values": [
                {
                  "name": "count",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "scatter": {
                "xAxis": {
                  "name": "dt",
                  "index": 0.0,
                  "aggr": "sum"
                }
              }
            }
          }
        ],
        "enabled": true,
        "editorSetting": {}
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "org.apache.hadoop.mapred.InvalidInputException: Input Pattern file:/opt/dataset/*.log.gz matches 0 files\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:285)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:228)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:202)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.ShuffleDependency.\u003cinit\u003e(Dependency.scala:91)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange$.prepareShuffleDependency(ShuffleExchange.scala:261)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange.prepareShuffleDependency(ShuffleExchange.scala:84)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange$$anonfun$doExecute$1.apply(ShuffleExchange.scala:121)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange$$anonfun$doExecute$1.apply(ShuffleExchange.scala:112)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange.doExecute(ShuffleExchange.scala:112)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:235)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:141)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:368)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:133)\n\tat org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2371)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n\tat org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2765)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2370)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2377)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2113)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2112)\n\tat org.apache.spark.sql.Dataset.withTypedCallback(Dataset.scala:2795)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2112)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2327)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.zeppelin.spark.ZeppelinContext.showDF(ZeppelinContext.java:235)\n\tat org.apache.zeppelin.spark.SparkSqlInterpreter.interpret(SparkSqlInterpreter.java:130)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:97)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:498)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:175)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:139)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:748)\n"
          }
        ]
      },
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "dt\tcount\n2003-04-10\t2887\n2003-04-11\t3708\n2003-04-12\t4019\n2003-04-13\t3577\n2003-04-14\t4329\n2003-04-15\t5667\n2003-04-16\t4641\n2003-04-17\t7551\n2003-04-18\t4461\n2003-04-19\t3156\n2003-04-20\t2996\n2003-04-21\t3981\n2003-04-22\t2953\n2003-04-23\t4671\n2003-04-24\t4112\n2003-04-25\t3719\n2003-04-26\t3155\n2003-04-27\t2993\n2003-04-28\t3243\n2003-04-29\t3393\n2003-04-30\t12876\n2003-05-01\t15430\n2003-06-01\t26428\n2003-06-02\t42074\n2003-06-03\t40205\n2003-06-04\t35653\n2003-06-05\t35637\n2003-06-06\t39829\n2003-06-07\t21977\n2003-06-08\t17474\n2003-06-09\t21580\n2003-06-10\t21320\n2003-06-11\t22397\n2003-06-12\t21467\n2003-06-13\t20259\n2003-06-14\t14644\n2003-06-15\t14280\n2003-06-16\t17892\n2003-06-17\t16365\n2003-06-18\t15031\n2003-06-19\t17939\n2003-06-20\t17072\n2003-06-21\t11735\n2003-06-22\t13130\n2003-06-23\t14849\n2003-06-24\t14125\n2003-06-25\t13860\n2003-06-26\t13249\n2003-06-27\t13165\n2003-06-28\t10485\n2003-06-29\t9713\n2003-06-30\t11902\n2003-07-01\t12044\n2003-07-02\t13006\n2003-07-03\t12441\n2003-07-04\t10933\n2003-07-05\t9542\n2003-07-06\t9641\n2003-07-07\t14629\n2003-07-08\t13014\n2003-07-09\t11586\n2003-07-10\t13501\n2003-07-11\t14426\n2003-07-12\t9536\n2003-07-13\t8944\n2003-07-14\t11933\n2003-07-15\t29487\n2003-07-16\t15923\n2003-07-17\t16165\n2003-07-18\t11493\n2003-07-19\t8896\n2003-07-20\t8566\n2003-07-21\t18395\n2003-07-22\t16211\n2003-07-23\t19238\n2003-07-24\t27495\n2003-07-25\t31316\n2003-07-26\t17002\n2003-07-27\t13018\n2003-07-28\t24203\n2003-07-29\t30942\n2003-07-30\t26312\n2003-07-31\t30395\n2003-08-01\t7566\n2003-09-01\t11412\n2003-09-02\t19481\n2003-09-03\t16354\n2003-09-04\t19376\n2003-09-05\t17778\n2003-09-06\t15703\n2003-09-07\t15184\n2003-09-08\t17329\n2003-09-09\t11812\n2003-09-10\t11441\n2003-09-11\t10434\n2003-09-12\t12148\n2003-09-13\t9415\n2003-09-14\t8891\n2003-09-15\t10579\n2003-09-16\t8953\n2003-09-17\t10747\n2003-09-18\t10015\n2003-09-19\t10567\n2003-09-20\t8765\n2003-09-21\t7609\n2003-09-22\t9584\n2003-09-23\t9187\n2003-09-24\t8692\n2003-09-25\t9311\n2003-09-26\t8610\n2003-09-27\t7252\n2003-09-28\t8341\n2003-09-29\t7478\n2003-09-30\t7415\n2003-10-01\t7255\n2003-10-02\t7064\n2003-10-03\t7649\n2003-10-04\t5487\n2003-10-05\t6541\n2003-10-06\t6934\n2003-10-07\t7860\n2003-10-08\t7295\n2003-10-09\t8150\n2003-10-10\t12405\n2003-10-11\t8214\n2003-10-12\t12826\n2003-10-13\t8410\n2003-10-14\t7928\n2003-10-15\t7805\n2003-10-16\t9090\n2003-10-17\t13420\n2003-10-18\t9902\n2003-10-19\t8197\n2003-10-20\t11596\n2003-10-21\t11306\n2003-10-22\t11890\n2003-10-23\t9965\n2003-10-24\t9609\n2003-10-25\t7395\n2003-10-26\t7576\n2003-10-27\t9795\n2003-10-28\t9847\n2003-10-29\t9155\n2003-10-30\t9248\n2003-10-31\t9290\n2003-11-01\t8037\n2003-11-02\t7950\n2003-11-03\t8968\n2003-11-04\t12372\n2003-11-05\t8444\n2003-11-06\t8465\n2003-11-07\t8529\n2003-11-08\t7546\n2003-11-09\t7035\n2003-11-10\t8666\n2003-11-11\t9764\n2003-11-12\t9639\n2003-11-13\t10155\n2003-11-14\t9522\n2003-11-15\t7933\n2003-11-16\t7597\n2003-11-17\t9456\n2003-11-18\t9623\n2003-11-19\t23667\n2003-11-20\t14780\n2003-11-21\t12924\n2003-11-22\t10016\n2003-11-23\t9584\n2003-11-24\t11046\n2003-11-25\t11373\n2003-11-26\t11706\n2003-11-27\t4095\n"
      },
      "apps": [],
      "jobName": "paragraph_1439863862677_2146849855",
      "id": "20150818-021102_2042086141",
      "dateCreated": "Aug 18, 2015 2:11:02 AM",
      "dateStarted": "Sep 8, 2017 1:34:16 PM",
      "dateFinished": "Sep 8, 2017 1:34:18 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md ## User-agent distribution by day",
      "user": "anonymous",
      "dateUpdated": "Sep 8, 2017 1:34:11 PM",
      "config": {
        "colWidth": 12.0,
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "editorSetting": {}
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eUser-agent distribution by day\u003c/h2\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eUser-agent distribution by day\u003c/h2\u003e\n"
      },
      "apps": [],
      "jobName": "paragraph_1440376052810_-1091679936",
      "id": "20150824-002732_395517427",
      "dateCreated": "Aug 24, 2015 12:27:32 AM",
      "dateStarted": "Sep 8, 2017 1:34:11 PM",
      "dateFinished": "Sep 8, 2017 1:34:12 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql\nSELECT from_unixtime(datetime, \u0027yyyy-MM-dd\u0027) AS dt, userAgent, COUNT(*) as count \nFROM logs\nWHERE userAgent RLIKE \u0027^Mozilla/[0-9]\\.0$\u0027\nGROUP BY from_unixtime(datetime, \u0027yyyy-MM-dd\u0027), userAgent\nORDER BY dt",
      "user": "anonymous",
      "dateUpdated": "Sep 8, 2017 1:34:11 PM",
      "config": {
        "colWidth": 12.0,
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "stackedAreaChart",
              "height": 300.0,
              "optionOpen": false,
              "keys": [
                {
                  "name": "dt",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "values": [
                {
                  "name": "count",
                  "index": 2.0,
                  "aggr": "sum"
                }
              ],
              "groups": [
                {
                  "name": "userAgent",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ],
              "scatter": {
                "xAxis": {
                  "name": "dt",
                  "index": 0.0,
                  "aggr": "sum"
                },
                "yAxis": {
                  "name": "userAgent",
                  "index": 1.0,
                  "aggr": "sum"
                }
              }
            }
          }
        ],
        "enabled": true,
        "editorSetting": {}
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "org.apache.hadoop.mapred.InvalidInputException: Input Pattern file:/opt/dataset/*.log.gz matches 0 files\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:285)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:228)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:202)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.ShuffleDependency.\u003cinit\u003e(Dependency.scala:91)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange$.prepareShuffleDependency(ShuffleExchange.scala:261)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange.prepareShuffleDependency(ShuffleExchange.scala:84)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange$$anonfun$doExecute$1.apply(ShuffleExchange.scala:121)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange$$anonfun$doExecute$1.apply(ShuffleExchange.scala:112)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange.doExecute(ShuffleExchange.scala:112)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:235)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:141)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:368)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:133)\n\tat org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2371)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n\tat org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2765)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2370)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2377)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2113)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2112)\n\tat org.apache.spark.sql.Dataset.withTypedCallback(Dataset.scala:2795)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2112)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2327)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.zeppelin.spark.ZeppelinContext.showDF(ZeppelinContext.java:235)\n\tat org.apache.zeppelin.spark.SparkSqlInterpreter.interpret(SparkSqlInterpreter.java:130)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:97)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:498)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:175)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:139)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:748)\n"
          }
        ]
      },
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "dt\tuserAgent\tcount\n2003-04-05\tMozilla/4.0\t1\n2003-04-06\tMozilla/4.0\t1\n2003-04-10\tMozilla/4.0\t1741\n2003-04-10\tMozilla/5.0\t262\n2003-04-10\tMozilla/2.0\t160\n2003-04-10\tMozilla/3.0\t12\n2003-04-11\tMozilla/2.0\t16\n2003-04-11\tMozilla/3.0\t9\n2003-04-11\tMozilla/5.0\t350\n2003-04-11\tMozilla/4.0\t2274\n2003-04-12\tMozilla/3.0\t76\n2003-04-12\tMozilla/2.0\t22\n2003-04-12\tMozilla/4.0\t2119\n2003-04-12\tMozilla/5.0\t313\n2003-04-13\tMozilla/2.0\t3\n2003-04-13\tMozilla/4.0\t2127\n2003-04-13\tMozilla/3.0\t6\n2003-04-13\tMozilla/5.0\t512\n2003-04-14\tMozilla/5.0\t592\n2003-04-14\tMozilla/2.0\t173\n2003-04-14\tMozilla/4.0\t2589\n2003-04-14\tMozilla/3.0\t33\n2003-04-15\tMozilla/3.0\t132\n2003-04-15\tMozilla/2.0\t9\n2003-04-15\tMozilla/5.0\t772\n2003-04-15\tMozilla/4.0\t3493\n2003-04-16\tMozilla/2.0\t272\n2003-04-16\tMozilla/4.0\t2558\n2003-04-16\tMozilla/3.0\t21\n2003-04-16\tMozilla/5.0\t449\n2003-04-17\tMozilla/3.0\t14\n2003-04-17\tMozilla/5.0\t891\n2003-04-17\tMozilla/4.0\t4755\n2003-04-17\tMozilla/2.0\t776\n2003-04-18\tMozilla/4.0\t2958\n2003-04-18\tMozilla/5.0\t455\n2003-04-18\tMozilla/3.0\t10\n2003-04-18\tMozilla/2.0\t1\n2003-04-19\tMozilla/5.0\t306\n2003-04-19\tMozilla/4.0\t1952\n2003-04-19\tMozilla/3.0\t5\n2003-04-19\tMozilla/2.0\t2\n2003-04-20\tMozilla/3.0\t3\n2003-04-20\tMozilla/5.0\t428\n2003-04-20\tMozilla/4.0\t1795\n2003-04-21\tMozilla/3.0\t30\n2003-04-21\tMozilla/5.0\t503\n2003-04-21\tMozilla/4.0\t2321\n2003-04-22\tMozilla/2.0\t3\n2003-04-22\tMozilla/4.0\t1911\n2003-04-22\tMozilla/3.0\t7\n2003-04-22\tMozilla/5.0\t330\n2003-04-23\tMozilla/3.0\t10\n2003-04-23\tMozilla/5.0\t845\n2003-04-23\tMozilla/4.0\t2685\n2003-04-23\tMozilla/2.0\t1\n2003-04-24\tMozilla/4.0\t2471\n2003-04-24\tMozilla/5.0\t632\n2003-04-24\tMozilla/3.0\t18\n2003-04-24\tMozilla/2.0\t10\n2003-04-25\tMozilla/5.0\t315\n2003-04-25\tMozilla/4.0\t1866\n2003-04-25\tMozilla/2.0\t9\n2003-04-25\tMozilla/3.0\t4\n2003-04-26\tMozilla/5.0\t255\n2003-04-26\tMozilla/3.0\t2\n2003-04-26\tMozilla/4.0\t1433\n2003-04-27\tMozilla/3.0\t11\n2003-04-27\tMozilla/4.0\t1474\n2003-04-27\tMozilla/5.0\t288\n2003-04-27\tMozilla/2.0\t10\n2003-04-28\tMozilla/4.0\t1624\n2003-04-28\tMozilla/5.0\t318\n2003-04-28\tMozilla/2.0\t1\n2003-04-28\tMozilla/3.0\t7\n2003-04-29\tMozilla/5.0\t309\n2003-04-29\tMozilla/3.0\t10\n2003-04-29\tMozilla/4.0\t1919\n2003-04-30\tMozilla/4.0\t7463\n2003-04-30\tMozilla/5.0\t1235\n2003-04-30\tMozilla/3.0\t66\n2003-04-30\tMozilla/2.0\t237\n2003-05-01\tMozilla/5.0\t1618\n2003-05-01\tMozilla/3.0\t16\n2003-05-01\tMozilla/4.0\t11439\n2003-06-01\tMozilla/2.0\t9\n2003-06-01\tMozilla/4.0\t20131\n2003-06-01\tMozilla/3.0\t142\n2003-06-01\tMozilla/1.0\t1\n2003-06-01\tMozilla/5.0\t4242\n2003-06-02\tMozilla/3.0\t485\n2003-06-02\tMozilla/5.0\t4279\n2003-06-02\tMozilla/4.0\t33637\n2003-06-02\tMozilla/2.0\t11\n2003-06-02\tMozilla/1.0\t1\n2003-06-03\tMozilla/4.0\t32672\n2003-06-03\tMozilla/5.0\t2960\n2003-06-03\tMozilla/3.0\t37\n2003-06-03\tMozilla/2.0\t23\n2003-06-04\tMozilla/2.0\t16\n2003-06-04\tMozilla/5.0\t2638\n2003-06-04\tMozilla/1.0\t1\n2003-06-04\tMozilla/4.0\t28814\n2003-06-04\tMozilla/3.0\t69\n2003-06-05\tMozilla/5.0\t2795\n2003-06-05\tMozilla/3.0\t166\n2003-06-05\tMozilla/2.0\t13\n2003-06-05\tMozilla/4.0\t27949\n2003-06-06\tMozilla/2.0\t14\n2003-06-06\tMozilla/3.0\t87\n2003-06-06\tMozilla/4.0\t28890\n2003-06-06\tMozilla/5.0\t2981\n2003-06-07\tMozilla/4.0\t16210\n2003-06-07\tMozilla/2.0\t7\n2003-06-07\tMozilla/5.0\t1580\n2003-06-07\tMozilla/3.0\t95\n2003-06-08\tMozilla/1.0\t1\n2003-06-08\tMozilla/5.0\t1427\n2003-06-08\tMozilla/3.0\t14\n2003-06-08\tMozilla/2.0\t6\n2003-06-08\tMozilla/4.0\t12691\n2003-06-09\tMozilla/4.0\t16396\n2003-06-09\tMozilla/3.0\t20\n2003-06-09\tMozilla/5.0\t1924\n2003-06-09\tMozilla/2.0\t33\n2003-06-09\tMozilla/1.0\t1\n2003-06-10\tMozilla/5.0\t1692\n2003-06-10\tMozilla/2.0\t8\n2003-06-10\tMozilla/1.0\t1\n2003-06-10\tMozilla/4.0\t16918\n2003-06-10\tMozilla/3.0\t71\n2003-06-11\tMozilla/5.0\t1552\n2003-06-11\tMozilla/2.0\t10\n2003-06-11\tMozilla/4.0\t18207\n2003-06-11\tMozilla/3.0\t17\n2003-06-12\tMozilla/3.0\t64\n2003-06-12\tMozilla/4.0\t17455\n2003-06-12\tMozilla/5.0\t1606\n2003-06-12\tMozilla/2.0\t6\n2003-06-13\tMozilla/4.0\t15671\n2003-06-13\tMozilla/5.0\t1520\n2003-06-13\tMozilla/2.0\t11\n2003-06-13\tMozilla/1.0\t2\n2003-06-13\tMozilla/3.0\t75\n2003-06-14\tMozilla/5.0\t840\n2003-06-14\tMozilla/3.0\t26\n2003-06-14\tMozilla/2.0\t4\n2003-06-14\tMozilla/4.0\t9034\n2003-06-15\tMozilla/5.0\t793\n2003-06-15\tMozilla/4.0\t8778\n2003-06-15\tMozilla/2.0\t6\n2003-06-15\tMozilla/3.0\t41\n2003-06-16\tMozilla/3.0\t98\n2003-06-16\tMozilla/5.0\t1521\n2003-06-16\tMozilla/4.0\t13141\n2003-06-16\tMozilla/2.0\t6\n2003-06-17\tMozilla/4.0\t12113\n2003-06-17\tMozilla/1.0\t1\n2003-06-17\tMozilla/5.0\t1583\n2003-06-17\tMozilla/2.0\t4\n2003-06-17\tMozilla/3.0\t52\n2003-06-18\tMozilla/2.0\t2\n2003-06-18\tMozilla/4.0\t11696\n2003-06-18\tMozilla/5.0\t1158\n2003-06-18\tMozilla/3.0\t21\n2003-06-19\tMozilla/3.0\t33\n2003-06-19\tMozilla/2.0\t1\n2003-06-19\tMozilla/4.0\t12432\n2003-06-19\tMozilla/5.0\t2550\n2003-06-20\tMozilla/4.0\t12691\n2003-06-20\tMozilla/5.0\t2098\n2003-06-20\tMozilla/6.0\t1\n2003-06-20\tMozilla/3.0\t48\n2003-06-20\tMozilla/2.0\t4\n2003-06-21\tMozilla/4.0\t8206\n2003-06-21\tMozilla/2.0\t4\n2003-06-21\tMozilla/3.0\t118\n2003-06-21\tMozilla/5.0\t1108\n2003-06-22\tMozilla/3.0\t34\n2003-06-22\tMozilla/5.0\t1101\n2003-06-22\tMozilla/4.0\t7475\n2003-06-22\tMozilla/2.0\t7\n2003-06-23\tMozilla/4.0\t11353\n2003-06-23\tMozilla/5.0\t1372\n2003-06-23\tMozilla/2.0\t5\n2003-06-23\tMozilla/3.0\t32\n2003-06-24\tMozilla/2.0\t47\n2003-06-24\tMozilla/5.0\t1142\n2003-06-24\tMozilla/3.0\t11\n2003-06-24\tMozilla/4.0\t11063\n2003-06-25\tMozilla/3.0\t13\n2003-06-25\tMozilla/5.0\t1207\n2003-06-25\tMozilla/2.0\t8\n2003-06-25\tMozilla/4.0\t10886\n2003-06-26\tMozilla/4.0\t10200\n2003-06-26\tMozilla/5.0\t1192\n2003-06-26\tMozilla/3.0\t70\n2003-06-26\tMozilla/2.0\t3\n2003-06-27\tMozilla/5.0\t1365\n2003-06-27\tMozilla/2.0\t9\n2003-06-27\tMozilla/4.0\t9832\n2003-06-27\tMozilla/3.0\t53\n2003-06-28\tMozilla/2.0\t1\n2003-06-28\tMozilla/3.0\t16\n2003-06-28\tMozilla/5.0\t731\n2003-06-28\tMozilla/4.0\t7110\n2003-06-29\tMozilla/4.0\t6431\n2003-06-29\tMozilla/2.0\t6\n2003-06-29\tMozilla/3.0\t10\n2003-06-29\tMozilla/5.0\t883\n2003-06-30\tMozilla/5.0\t903\n2003-06-30\tMozilla/2.0\t57\n2003-06-30\tMozilla/1.0\t2\n2003-06-30\tMozilla/3.0\t24\n2003-06-30\tMozilla/4.0\t8822\n2003-07-01\tMozilla/3.0\t19\n2003-07-01\tMozilla/4.0\t9012\n2003-07-01\tMozilla/5.0\t1021\n2003-07-01\tMozilla/2.0\t149\n2003-07-02\tMozilla/5.0\t1524\n2003-07-02\tMozilla/2.0\t68\n2003-07-02\tMozilla/4.0\t9238\n2003-07-02\tMozilla/3.0\t12\n2003-07-03\tMozilla/2.0\t76\n2003-07-03\tMozilla/5.0\t1289\n2003-07-03\tMozilla/3.0\t50\n2003-07-03\tMozilla/4.0\t8754\n2003-07-04\tMozilla/3.0\t22\n2003-07-04\tMozilla/4.0\t7985\n2003-07-04\tMozilla/6.0\t1\n2003-07-04\tMozilla/5.0\t1145\n2003-07-04\tMozilla/2.0\t7\n2003-07-05\tMozilla/2.0\t166\n2003-07-05\tMozilla/3.0\t12\n2003-07-05\tMozilla/4.0\t6821\n2003-07-05\tMozilla/5.0\t1009\n2003-07-06\tMozilla/3.0\t9\n2003-07-06\tMozilla/2.0\t1\n2003-07-06\tMozilla/4.0\t7209\n2003-07-06\tMozilla/5.0\t1094\n2003-07-06\tMozilla/1.0\t1\n2003-07-07\tMozilla/4.0\t11184\n2003-07-07\tMozilla/3.0\t19\n2003-07-07\tMozilla/2.0\t9\n2003-07-07\tMozilla/5.0\t1732\n2003-07-08\tMozilla/5.0\t1060\n2003-07-08\tMozilla/3.0\t50\n2003-07-08\tMozilla/4.0\t9542\n2003-07-08\tMozilla/2.0\t4\n2003-07-08\tMozilla/6.0\t4\n2003-07-09\tMozilla/5.0\t1037\n2003-07-09\tMozilla/1.0\t1\n2003-07-09\tMozilla/3.0\t57\n2003-07-09\tMozilla/2.0\t1\n2003-07-09\tMozilla/4.0\t8526\n2003-07-10\tMozilla/3.0\t54\n2003-07-10\tMozilla/5.0\t990\n2003-07-10\tMozilla/2.0\t1\n2003-07-10\tMozilla/4.0\t9105\n2003-07-11\tMozilla/4.0\t8588\n2003-07-11\tMozilla/5.0\t1282\n2003-07-11\tMozilla/2.0\t2\n2003-07-11\tMozilla/3.0\t316\n2003-07-12\tMozilla/2.0\t3\n2003-07-12\tMozilla/3.0\t8\n2003-07-12\tMozilla/4.0\t6546\n2003-07-12\tMozilla/5.0\t1127\n2003-07-13\tMozilla/4.0\t6317\n2003-07-13\tMozilla/2.0\t1\n2003-07-13\tMozilla/3.0\t15\n2003-07-13\tMozilla/5.0\t827\n2003-07-14\tMozilla/5.0\t1234\n2003-07-14\tMozilla/2.0\t7\n2003-07-14\tMozilla/3.0\t17\n2003-07-14\tMozilla/4.0\t8643\n2003-07-15\tMozilla/3.0\t9\n2003-07-15\tMozilla/2.0\t2\n2003-07-15\tMozilla/5.0\t1803\n2003-07-15\tMozilla/4.0\t25724\n2003-07-16\tMozilla/5.0\t1375\n2003-07-16\tMozilla/2.0\t1\n2003-07-16\tMozilla/4.0\t12475\n2003-07-16\tMozilla/3.0\t22\n2003-07-17\tMozilla/3.0\t25\n2003-07-17\tMozilla/5.0\t2907\n2003-07-17\tMozilla/4.0\t9874\n2003-07-17\tMozilla/2.0\t906\n2003-07-18\tMozilla/3.0\t22\n2003-07-18\tMozilla/4.0\t7919\n2003-07-18\tMozilla/5.0\t1207\n2003-07-18\tMozilla/2.0\t295\n2003-07-19\tMozilla/1.0\t51\n2003-07-19\tMozilla/4.0\t5693\n2003-07-19\tMozilla/3.0\t31\n2003-07-19\tMozilla/5.0\t897\n2003-07-19\tMozilla/2.0\t5\n2003-07-20\tMozilla/4.0\t5323\n2003-07-20\tMozilla/3.0\t8\n2003-07-20\tMozilla/5.0\t753\n2003-07-20\tMozilla/2.0\t1\n2003-07-20\tMozilla/1.0\t6\n2003-07-21\tMozilla/2.0\t4\n2003-07-21\tMozilla/1.0\t6\n2003-07-21\tMozilla/3.0\t16\n2003-07-21\tMozilla/5.0\t1603\n2003-07-21\tMozilla/4.0\t14362\n2003-07-22\tMozilla/2.0\t1\n2003-07-22\tMozilla/4.0\t11867\n2003-07-22\tMozilla/3.0\t24\n2003-07-22\tMozilla/5.0\t1542\n2003-07-23\tMozilla/3.0\t52\n2003-07-23\tMozilla/4.0\t14776\n2003-07-23\tMozilla/2.0\t4\n2003-07-23\tMozilla/1.0\t1\n2003-07-23\tMozilla/5.0\t1859\n2003-07-24\tMozilla/5.0\t2270\n2003-07-24\tMozilla/2.0\t9\n2003-07-24\tMozilla/1.0\t2\n2003-07-24\tMozilla/4.0\t23090\n2003-07-24\tMozilla/3.0\t30\n2003-07-24\tMozilla/7.0\t1\n2003-07-25\tMozilla/5.0\t4172\n2003-07-25\tMozilla/1.0\t1\n2003-07-25\tMozilla/4.0\t23055\n2003-07-25\tMozilla/3.0\t23\n2003-07-25\tMozilla/2.0\t10\n2003-07-26\tMozilla/1.0\t2\n2003-07-26\tMozilla/2.0\t3\n2003-07-26\tMozilla/5.0\t2044\n2003-07-26\tMozilla/3.0\t20\n2003-07-26\tMozilla/4.0\t13015\n2003-07-27\tMozilla/1.0\t1\n2003-07-27\tMozilla/2.0\t4\n2003-07-27\tMozilla/3.0\t16\n2003-07-27\tMozilla/4.0\t10168\n2003-07-27\tMozilla/5.0\t1382\n2003-07-28\tMozilla/4.0\t19536\n2003-07-28\tMozilla/2.0\t5\n2003-07-28\tMozilla/5.0\t2363\n2003-07-28\tMozilla/1.0\t1\n2003-07-28\tMozilla/6.0\t1\n2003-07-28\tMozilla/3.0\t8\n2003-07-29\tMozilla/5.0\t3338\n2003-07-29\tMozilla/3.0\t19\n2003-07-29\tMozilla/2.0\t4\n2003-07-29\tMozilla/4.0\t25417\n2003-07-29\tMozilla/1.0\t1\n2003-07-30\tMozilla/4.0\t22130\n2003-07-30\tMozilla/1.0\t2\n2003-07-30\tMozilla/5.0\t2276\n2003-07-30\tMozilla/3.0\t15\n2003-07-30\tMozilla/2.0\t4\n2003-07-31\tMozilla/3.0\t21\n2003-07-31\tMozilla/2.0\t2\n2003-07-31\tMozilla/5.0\t2483\n2003-07-31\tMozilla/4.0\t23010\n2003-08-01\tMozilla/5.0\t770\n2003-08-01\tMozilla/4.0\t6238\n2003-08-01\tMozilla/3.0\t5\n2003-08-01\tMozilla/2.0\t1\n2003-09-01\tMozilla/3.0\t5\n2003-09-01\tMozilla/5.0\t706\n2003-09-01\tMozilla/2.0\t2\n2003-09-01\tMozilla/4.0\t9637\n2003-09-01\tMozilla/6.0\t1\n2003-09-02\tMozilla/3.0\t25\n2003-09-02\tMozilla/5.0\t1377\n2003-09-02\tMozilla/4.0\t16333\n2003-09-02\tMozilla/2.0\t2\n2003-09-03\tMozilla/4.0\t12925\n2003-09-03\tMozilla/5.0\t1557\n2003-09-03\tMozilla/2.0\t1\n2003-09-03\tMozilla/3.0\t15\n2003-09-04\tMozilla/2.0\t21\n2003-09-04\tMozilla/5.0\t3533\n2003-09-04\tMozilla/4.0\t13521\n2003-09-04\tMozilla/3.0\t20\n2003-09-05\tMozilla/2.0\t13\n2003-09-05\tMozilla/3.0\t15\n2003-09-05\tMozilla/5.0\t1857\n2003-09-05\tMozilla/4.0\t13979\n2003-09-06\tMozilla/2.0\t51\n2003-09-06\tMozilla/3.0\t2638\n2003-09-06\tMozilla/4.0\t10110\n2003-09-06\tMozilla/5.0\t1090\n2003-09-07\tMozilla/4.0\t10087\n2003-09-07\tMozilla/3.0\t16\n2003-09-07\tMozilla/2.0\t1\n2003-09-07\tMozilla/5.0\t3115\n2003-09-08\tMozilla/5.0\t2418\n2003-09-08\tMozilla/3.0\t15\n2003-09-08\tMozilla/4.0\t12364\n2003-09-08\tMozilla/2.0\t13\n2003-09-09\tMozilla/4.0\t8748\n2003-09-09\tMozilla/3.0\t11\n2003-09-09\tMozilla/5.0\t1292\n2003-09-09\tMozilla/2.0\t4\n2003-09-10\tMozilla/3.0\t13\n2003-09-10\tMozilla/5.0\t1250\n2003-09-10\tMozilla/4.0\t7925\n2003-09-11\tMozilla/4.0\t7825\n2003-09-11\tMozilla/2.0\t10\n2003-09-11\tMozilla/5.0\t1049\n2003-09-11\tMozilla/3.0\t15\n2003-09-12\tMozilla/2.0\t10\n2003-09-12\tMozilla/3.0\t14\n2003-09-12\tMozilla/4.0\t7710\n2003-09-12\tMozilla/5.0\t1419\n2003-09-13\tMozilla/3.0\t8\n2003-09-13\tMozilla/4.0\t5389\n2003-09-13\tMozilla/5.0\t866\n2003-09-14\tMozilla/3.0\t7\n2003-09-14\tMozilla/5.0\t874\n2003-09-14\tMozilla/4.0\t5269\n2003-09-15\tMozilla/6.0\t1\n2003-09-15\tMozilla/4.0\t6902\n2003-09-15\tMozilla/3.0\t7\n2003-09-15\tMozilla/2.0\t42\n2003-09-15\tMozilla/5.0\t876\n2003-09-16\tMozilla/5.0\t961\n2003-09-16\tMozilla/3.0\t9\n2003-09-16\tMozilla/4.0\t6541\n2003-09-16\tMozilla/2.0\t2\n2003-09-17\tMozilla/4.0\t7632\n2003-09-17\tMozilla/2.0\t4\n2003-09-17\tMozilla/3.0\t24\n2003-09-17\tMozilla/5.0\t1115\n2003-09-18\tMozilla/3.0\t18\n2003-09-18\tMozilla/4.0\t7236\n2003-09-18\tMozilla/5.0\t1048\n2003-09-18\tMozilla/2.0\t10\n2003-09-19\tMozilla/5.0\t1335\n2003-09-19\tMozilla/2.0\t1\n2003-09-19\tMozilla/4.0\t6908\n2003-09-19\tMozilla/3.0\t13\n2003-09-20\tMozilla/5.0\t1062\n2003-09-20\tMozilla/4.0\t5589\n2003-09-20\tMozilla/3.0\t10\n2003-09-20\tMozilla/2.0\t5\n2003-09-21\tMozilla/3.0\t10\n2003-09-21\tMozilla/4.0\t4814\n2003-09-21\tMozilla/2.0\t11\n2003-09-21\tMozilla/5.0\t1074\n2003-09-22\tMozilla/5.0\t1078\n2003-09-22\tMozilla/2.0\t5\n2003-09-22\tMozilla/3.0\t20\n2003-09-22\tMozilla/4.0\t6330\n2003-09-23\tMozilla/5.0\t1208\n2003-09-23\tMozilla/2.0\t3\n2003-09-23\tMozilla/3.0\t7\n2003-09-23\tMozilla/4.0\t5801\n2003-09-24\tMozilla/2.0\t1\n2003-09-24\tMozilla/4.0\t6078\n2003-09-24\tMozilla/5.0\t1006\n2003-09-24\tMozilla/3.0\t14\n2003-09-25\tMozilla/3.0\t22\n2003-09-25\tMozilla/4.0\t6625\n2003-09-25\tMozilla/5.0\t1022\n2003-09-25\tMozilla/2.0\t2\n2003-09-26\tMozilla/3.0\t4\n2003-09-26\tMozilla/5.0\t991\n2003-09-26\tMozilla/4.0\t5948\n2003-09-26\tMozilla/6.0\t7\n2003-09-26\tMozilla/2.0\t3\n2003-09-27\tMozilla/5.0\t674\n2003-09-27\tMozilla/3.0\t5\n2003-09-27\tMozilla/4.0\t4691\n2003-09-28\tMozilla/3.0\t7\n2003-09-28\tMozilla/5.0\t559\n2003-09-28\tMozilla/4.0\t4241\n2003-09-29\tMozilla/2.0\t71\n2003-09-29\tMozilla/6.0\t1\n2003-09-29\tMozilla/3.0\t7\n2003-09-29\tMozilla/5.0\t850\n2003-09-29\tMozilla/4.0\t4922\n2003-09-30\tMozilla/3.0\t10\n2003-09-30\tMozilla/2.0\t17\n2003-09-30\tMozilla/6.0\t3\n2003-09-30\tMozilla/4.0\t5177\n2003-09-30\tMozilla/5.0\t762\n2003-10-01\tMozilla/2.0\t11\n2003-10-01\tMozilla/5.0\t781\n2003-10-01\tMozilla/3.0\t6\n2003-10-01\tMozilla/4.0\t4958\n2003-10-02\tMozilla/2.0\t9\n2003-10-02\tMozilla/5.0\t754\n2003-10-02\tMozilla/3.0\t7\n2003-10-02\tMozilla/4.0\t4825\n2003-10-03\tMozilla/2.0\t43\n2003-10-03\tMozilla/5.0\t730\n2003-10-03\tMozilla/3.0\t8\n2003-10-03\tMozilla/4.0\t5194\n2003-10-04\tMozilla/3.0\t11\n2003-10-04\tMozilla/4.0\t3584\n2003-10-04\tMozilla/5.0\t567\n2003-10-05\tMozilla/4.0\t3976\n2003-10-05\tMozilla/5.0\t583\n2003-10-05\tMozilla/3.0\t17\n2003-10-06\tMozilla/5.0\t749\n2003-10-06\tMozilla/3.0\t12\n2003-10-06\tMozilla/2.0\t1\n2003-10-06\tMozilla/4.0\t4458\n2003-10-07\tMozilla/4.0\t4999\n2003-10-07\tMozilla/3.0\t36\n2003-10-07\tMozilla/5.0\t970\n2003-10-08\tMozilla/3.0\t57\n2003-10-08\tMozilla/4.0\t4455\n2003-10-08\tMozilla/6.0\t1\n2003-10-08\tMozilla/5.0\t912\n2003-10-09\tMozilla/3.0\t10\n2003-10-09\tMozilla/4.0\t5140\n2003-10-09\tMozilla/5.0\t1071\n2003-10-09\tMozilla/2.0\t2\n2003-10-10\tMozilla/5.0\t1144\n2003-10-10\tMozilla/3.0\t5\n2003-10-10\tMozilla/6.0\t1\n2003-10-10\tMozilla/4.0\t8099\n2003-10-10\tMozilla/2.0\t43\n2003-10-11\tMozilla/5.0\t744\n2003-10-11\tMozilla/4.0\t5578\n2003-10-11\tMozilla/3.0\t5\n2003-10-12\tMozilla/3.0\t6\n2003-10-12\tMozilla/2.0\t13\n2003-10-12\tMozilla/5.0\t815\n2003-10-12\tMozilla/4.0\t5981\n2003-10-13\tMozilla/3.0\t8\n2003-10-13\tMozilla/2.0\t12\n2003-10-13\tMozilla/5.0\t991\n2003-10-13\tMozilla/4.0\t5680\n2003-10-14\tMozilla/5.0\t924\n2003-10-14\tMozilla/4.0\t5201\n2003-10-14\tMozilla/3.0\t8\n2003-10-15\tMozilla/5.0\t1099\n2003-10-15\tMozilla/4.0\t4644\n2003-10-15\tMozilla/3.0\t19\n2003-10-16\tMozilla/5.0\t1195\n2003-10-16\tMozilla/4.0\t6039\n2003-10-16\tMozilla/2.0\t10\n2003-10-16\tMozilla/3.0\t24\n2003-10-17\tMozilla/5.0\t1411\n2003-10-17\tMozilla/3.0\t20\n2003-10-17\tMozilla/4.0\t9449\n2003-10-17\tMozilla/2.0\t25\n2003-10-18\tMozilla/4.0\t6916\n2003-10-18\tMozilla/3.0\t16\n2003-10-18\tMozilla/2.0\t29\n2003-10-18\tMozilla/5.0\t966\n2003-10-19\tMozilla/3.0\t17\n2003-10-19\tMozilla/5.0\t1005\n2003-10-19\tMozilla/4.0\t5484\n2003-10-20\tMozilla/4.0\t7919\n2003-10-20\tMozilla/3.0\t21\n2003-10-20\tMozilla/5.0\t1107\n2003-10-21\tMozilla/2.0\t4\n2003-10-21\tMozilla/4.0\t7169\n2003-10-21\tMozilla/5.0\t1021\n2003-10-21\tMozilla/3.0\t16\n2003-10-22\tMozilla/4.0\t7223\n2003-10-22\tMozilla/3.0\t8\n2003-10-22\tMozilla/5.0\t1047\n2003-10-23\tMozilla/5.0\t1001\n2003-10-23\tMozilla/4.0\t6486\n2003-10-23\tMozilla/3.0\t16\n2003-10-23\tMozilla/2.0\t2\n2003-10-24\tMozilla/4.0\t6587\n2003-10-24\tMozilla/5.0\t925\n2003-10-24\tMozilla/2.0\t7\n2003-10-24\tMozilla/3.0\t9\n2003-10-25\tMozilla/5.0\t683\n2003-10-25\tMozilla/2.0\t4\n2003-10-25\tMozilla/3.0\t16\n2003-10-25\tMozilla/4.0\t4855\n2003-10-26\tMozilla/4.0\t5082\n2003-10-26\tMozilla/3.0\t7\n2003-10-26\tMozilla/2.0\t55\n2003-10-26\tMozilla/5.0\t715\n2003-10-27\tMozilla/3.0\t23\n2003-10-27\tMozilla/5.0\t956\n2003-10-27\tMozilla/4.0\t7009\n2003-10-28\tMozilla/3.0\t10\n2003-10-28\tMozilla/4.0\t6940\n2003-10-28\tMozilla/5.0\t959\n2003-10-28\tMozilla/2.0\t1\n2003-10-29\tMozilla/4.0\t6054\n2003-10-29\tMozilla/3.0\t20\n2003-10-29\tMozilla/6.0\t1\n2003-10-29\tMozilla/5.0\t1044\n2003-10-29\tMozilla/2.0\t2\n2003-10-30\tMozilla/2.0\t2\n2003-10-30\tMozilla/4.0\t5762\n2003-10-30\tMozilla/5.0\t994\n2003-10-30\tMozilla/3.0\t6\n2003-10-31\tMozilla/2.0\t2\n2003-10-31\tMozilla/4.0\t5494\n2003-10-31\tMozilla/3.0\t9\n2003-10-31\tMozilla/5.0\t1062\n2003-10-31\tMozilla/6.0\t1\n2003-11-01\tMozilla/3.0\t3\n2003-11-01\tMozilla/5.0\t904\n2003-11-01\tMozilla/2.0\t94\n2003-11-01\tMozilla/4.0\t4820\n2003-11-02\tMozilla/4.0\t5039\n2003-11-02\tMozilla/5.0\t839\n2003-11-02\tMozilla/3.0\t3\n2003-11-02\tMozilla/2.0\t6\n2003-11-03\tMozilla/3.0\t5\n2003-11-03\tMozilla/4.0\t5174\n2003-11-03\tMozilla/2.0\t7\n2003-11-03\tMozilla/5.0\t831\n2003-11-04\tMozilla/3.0\t14\n2003-11-04\tMozilla/4.0\t7045\n2003-11-04\tMozilla/5.0\t847\n2003-11-05\tMozilla/5.0\t878\n2003-11-05\tMozilla/4.0\t5262\n2003-11-05\tMozilla/6.0\t1\n2003-11-05\tMozilla/3.0\t7\n2003-11-06\tMozilla/5.0\t933\n2003-11-06\tMozilla/3.0\t18\n2003-11-06\tMozilla/2.0\t2\n2003-11-06\tMozilla/4.0\t5395\n2003-11-07\tMozilla/4.0\t5113\n2003-11-07\tMozilla/3.0\t6\n2003-11-07\tMozilla/2.0\t1\n2003-11-07\tMozilla/5.0\t1018\n2003-11-08\tMozilla/2.0\t125\n2003-11-08\tMozilla/5.0\t732\n2003-11-08\tMozilla/3.0\t3\n2003-11-08\tMozilla/4.0\t4293\n2003-11-09\tMozilla/3.0\t9\n2003-11-09\tMozilla/5.0\t800\n2003-11-09\tMozilla/4.0\t4118\n2003-11-09\tMozilla/2.0\t22\n2003-11-09\tMozilla/6.0\t1\n2003-11-10\tMozilla/4.0\t4925\n2003-11-10\tMozilla/3.0\t20\n2003-11-10\tMozilla/5.0\t1036\n2003-11-11\tMozilla/5.0\t1142\n2003-11-11\tMozilla/2.0\t2\n2003-11-11\tMozilla/4.0\t5123\n2003-11-11\tMozilla/3.0\t7\n2003-11-12\tMozilla/5.0\t1098\n2003-11-12\tMozilla/2.0\t481\n2003-11-12\tMozilla/3.0\t7\n2003-11-12\tMozilla/4.0\t5410\n2003-11-13\tMozilla/5.0\t1268\n2003-11-13\tMozilla/3.0\t10\n2003-11-13\tMozilla/2.0\t599\n2003-11-13\tMozilla/4.0\t5391\n2003-11-14\tMozilla/3.0\t3\n2003-11-14\tMozilla/5.0\t1117\n2003-11-14\tMozilla/4.0\t5250\n2003-11-15\tMozilla/2.0\t6\n2003-11-15\tMozilla/3.0\t3\n2003-11-15\tMozilla/5.0\t1005\n2003-11-15\tMozilla/4.0\t4557\n2003-11-16\tMozilla/4.0\t4330\n2003-11-16\tMozilla/3.0\t7\n2003-11-16\tMozilla/2.0\t4\n2003-11-16\tMozilla/5.0\t921\n2003-11-16\tMozilla/8.0\t1\n2003-11-17\tMozilla/4.0\t5384\n2003-11-17\tMozilla/3.0\t15\n2003-11-17\tMozilla/5.0\t1414\n2003-11-18\tMozilla/5.0\t1162\n2003-11-18\tMozilla/3.0\t19\n2003-11-18\tMozilla/4.0\t6085\n2003-11-19\tMozilla/4.0\t19309\n2003-11-19\tMozilla/3.0\t22\n2003-11-19\tMozilla/5.0\t1846\n2003-11-19\tMozilla/2.0\t6\n2003-11-20\tMozilla/2.0\t3\n2003-11-20\tMozilla/5.0\t1505\n2003-11-20\tMozilla/4.0\t10490\n2003-11-20\tMozilla/3.0\t9\n2003-11-21\tMozilla/5.0\t1763\n2003-11-21\tMozilla/2.0\t9\n2003-11-21\tMozilla/3.0\t10\n2003-11-21\tMozilla/4.0\t8372\n2003-11-22\tMozilla/3.0\t10\n2003-11-22\tMozilla/5.0\t1230\n2003-11-22\tMozilla/4.0\t6685\n2003-11-23\tMozilla/5.0\t1110\n2003-11-23\tMozilla/2.0\t4\n2003-11-23\tMozilla/4.0\t6178\n2003-11-23\tMozilla/3.0\t4\n2003-11-24\tMozilla/3.0\t20\n2003-11-24\tMozilla/2.0\t17\n2003-11-24\tMozilla/4.0\t6681\n2003-11-24\tMozilla/5.0\t1359\n2003-11-25\tMozilla/4.0\t6945\n2003-11-25\tMozilla/3.0\t7\n2003-11-25\tMozilla/2.0\t79\n2003-11-25\tMozilla/5.0\t1469\n2003-11-26\tMozilla/5.0\t1566\n2003-11-26\tMozilla/2.0\t5\n2003-11-26\tMozilla/4.0\t7007\n2003-11-26\tMozilla/3.0\t9\n2003-11-27\tMozilla/5.0\t382\n2003-11-27\tMozilla/4.0\t2705\n2003-11-27\tMozilla/3.0\t3\n"
      },
      "apps": [],
      "jobName": "paragraph_1440372634780_-517624481",
      "id": "20150823-233034_1070680357",
      "dateCreated": "Aug 23, 2015 11:30:34 PM",
      "dateStarted": "Sep 8, 2017 1:34:18 PM",
      "dateFinished": "Sep 8, 2017 1:34:18 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// This functions converts a IP String in its Numeric representation\n// Similar to MySQL Function INET_ATON: https://dev.mysql.com/doc/refman/5.0/en/miscellaneous-functions.html#function_inet-aton\n    def ipToNumber(ipAddr: String): Long \u003d {\n      try {\n        val parts \u003d ipAddr.split(\"\\\\.\")\n        parts(3).toLong + (parts(2).toLong * 256L) + (parts(1).toLong * 256L * 256L) + (parts(0).toLong * 256L * 256L * 256L)\n      } catch {\n        case e: Exception \u003d\u003e {\n          e.printStackTrace\n          0\n        }\n      }\n    }\n\n// Register the new Function to the SQLContext\nsqlContext.udf.register(\"INET_ATON\", (ip:String) \u003d\u003e ipToNumber(ip))\n\n\nval ipCSV \u003d sc.textFile(\"/opt/dataset/ipligence-lite.csv\")\n\ncase class IP(ipFrom: Long, ipTo: Long, country: String)\n\nval ips \u003d ipCSV.map { line \u003d\u003e\n      val values \u003d line.split(\",\")\n      IP(ipFrom \u003d values(0).replace(\"\\\"\", \"\").toLong,\n        ipTo \u003d values(1).replace(\"\\\"\", \"\").toLong,\n        country \u003d values(2).replace(\"\\\"\", \"\"))\n    }\n\n    val ipsDF \u003d ips.toDF\n    ipsDF.registerTempTable(\"ips\")\n    sqlContext.cacheTable(\"ips\")\n    \n    ",
      "user": "anonymous",
      "dateUpdated": "Sep 8, 2017 1:34:12 PM",
      "config": {
        "colWidth": 12.0,
        "tableHide": false,
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "editorSetting": {}
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nipToNumber: (ipAddr: String)Long\n\nres65: org.apache.spark.sql.expressions.UserDefinedFunction \u003d UserDefinedFunction(\u003cfunction1\u003e,LongType,Some(List(StringType)))\n\nipCSV: org.apache.spark.rdd.RDD[String] \u003d /opt/dataset/ipligence-lite.csv MapPartitionsRDD[65] at textFile at \u003cconsole\u003e:38\n\ndefined class IP\n\nips: org.apache.spark.rdd.RDD[IP] \u003d MapPartitionsRDD[66] at map at \u003cconsole\u003e:41\n\nipsDF: org.apache.spark.sql.DataFrame \u003d [ipFrom: bigint, ipTo: bigint ... 1 more field]\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"
          }
        ]
      },
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "ipToNumber: (ipAddr: String)Long\nres22: org.apache.spark.sql.UserDefinedFunction \u003d UserDefinedFunction(\u003cfunction1\u003e,LongType)\nipCSV: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[25] at textFile at \u003cconsole\u003e:28\ndefined class IP\nips: org.apache.spark.rdd.RDD[IP] \u003d MapPartitionsRDD[26] at map at \u003cconsole\u003e:31\nipsDF: org.apache.spark.sql.DataFrame \u003d [ipFrom: bigint, ipTo: bigint, country: string]\n"
      },
      "apps": [],
      "jobName": "paragraph_1440277668918_1145059537",
      "id": "20150822-210748_1256698294",
      "dateCreated": "Aug 22, 2015 9:07:48 PM",
      "dateStarted": "Sep 8, 2017 1:34:18 PM",
      "dateFinished": "Sep 8, 2017 1:34:22 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql CACHE TABLE tbl_ip_country AS\nSELECT logs.remoteIP, ips.country\nFROM logs INNER JOIN ips\n    ON \n    ips.ipFrom \u003c\u003d INET_ATON(logs.remoteIP) AND \n    ips.ipTo \u003e\u003d INET_ATON(logs.remoteIP)\nLIMIT 100",
      "user": "anonymous",
      "dateUpdated": "Sep 8, 2017 1:34:12 PM",
      "config": {
        "colWidth": 12.0,
        "tableHide": true,
        "editorHide": false,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [
                {
                  "name": "null",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "values": [],
              "groups": [],
              "scatter": {
                "xAxis": {
                  "name": "null",
                  "index": 0.0,
                  "aggr": "sum"
                }
              }
            }
          }
        ],
        "enabled": true,
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "Temporary table \u0027tbl_ip_country\u0027 already exists;\nset zeppelin.spark.sql.stacktrace \u003d true to see full stacktrace"
          }
        ]
      },
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "null\n"
      },
      "apps": [],
      "jobName": "paragraph_1440277856174_609366475",
      "id": "20150822-211056_569859568",
      "dateCreated": "Aug 22, 2015 9:10:56 PM",
      "dateStarted": "Sep 8, 2017 1:34:19 PM",
      "dateFinished": "Sep 8, 2017 1:34:22 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md ## Top Referrer Domains \u0026 Origin Countries",
      "user": "anonymous",
      "dateUpdated": "Sep 8, 2017 1:34:13 PM",
      "config": {
        "colWidth": 12.0,
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "editorSetting": {}
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eTop Referrer Domains \u0026amp; Origin Countries\u003c/h2\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eTop Referrer Domains \u0026amp; Origin Countries\u003c/h2\u003e\n"
      },
      "apps": [],
      "jobName": "paragraph_1440369875755_-830967664",
      "id": "20150823-224435_1998719818",
      "dateCreated": "Aug 23, 2015 10:44:35 PM",
      "dateStarted": "Sep 8, 2017 1:34:13 PM",
      "dateFinished": "Sep 8, 2017 1:34:13 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Extract the httpReferer host\nval results \u003d logRecords.map(r \u003d\u003e (r.httpReferer.getHost, 1)).\n// Filter those lines without httpReferer\nfilter(_._1 !\u003d null).\n// Sum records with same httpReferer, resulting a tupple like: (httpReferer, quantity)\nreduceByKey(_+_).\n// Invert the tuple (quantity, httpReferer)\nmap(_.swap).\n// Calculate Top\ntop(8)\n\n// Print results as table\n// so Zeppelin can show the results as charts\nprintln(\"%table\\tdomain\\tcount\")\nresults.foreach(r \u003d\u003e println(r._2 + \"\\t\" + r._1))",
      "user": "anonymous",
      "dateUpdated": "Sep 8, 2017 1:34:13 PM",
      "config": {
        "colWidth": 6.0,
        "tableHide": false,
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 228.0,
              "optionOpen": false,
              "keys": [
                {
                  "name": "domain",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "values": [
                {
                  "name": "count",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "scatter": {
                "yAxis": {
                  "name": "count",
                  "index": 1.0,
                  "aggr": "sum"
                }
              }
            }
          }
        ],
        "enabled": true,
        "editorSetting": {}
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\norg.apache.hadoop.mapred.InvalidInputException: Input Pattern file:/opt/dataset/*.log.gz matches 0 files\n  at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:285)\n  at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:228)\n  at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313)\n  at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:202)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n  at org.apache.spark.Partitioner$$anonfun$defaultPartitioner$2.apply(Partitioner.scala:66)\n  at org.apache.spark.Partitioner$$anonfun$defaultPartitioner$2.apply(Partitioner.scala:66)\n  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n  at scala.collection.immutable.List.map(List.scala:285)\n  at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:66)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)\n  ... 46 elided\n"
          }
        ]
      },
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "domain\tcount\nwww.waxy.org\t561939\nwww.google.com\t126799\nsearch.yahoo.com\t63361\nsearch.msn.com\t61847\nwww.teamabuse.com\t37159\nwaxy.org\t18329\nwww.google.ca\t17484\n50.lycos.com\t14260\n"
      },
      "apps": [],
      "jobName": "paragraph_1439841676518_224081683",
      "id": "20150817-200116_625479689",
      "dateCreated": "Aug 17, 2015 8:01:16 PM",
      "dateStarted": "Sep 8, 2017 1:34:22 PM",
      "dateFinished": "Sep 8, 2017 1:34:23 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql \nSELECT country, COUNT(1) AS count \nFROM tbl_ip_country\nGROUP BY country\nORDER BY count DESC\nLIMIT 8",
      "user": "anonymous",
      "dateUpdated": "Sep 8, 2017 1:34:13 PM",
      "config": {
        "colWidth": 6.0,
        "tableHide": false,
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "pieChart",
              "height": 300.0,
              "optionOpen": false,
              "keys": [
                {
                  "name": "country",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "values": [
                {
                  "name": "count",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "scatter": {
                "xAxis": {
                  "name": "country",
                  "index": 0.0,
                  "aggr": "sum"
                },
                "yAxis": {
                  "name": "count",
                  "index": 1.0,
                  "aggr": "sum"
                }
              }
            }
          }
        ],
        "enabled": true,
        "editorSetting": {}
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/opt/dataset/ipligence-lite.csv\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:285)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:228)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:202)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.CartesianRDD.\u003cinit\u003e(CartesianRDD.scala:56)\n\tat org.apache.spark.sql.execution.joins.UnsafeCartesianRDD.\u003cinit\u003e(CartesianProductExec.scala:38)\n\tat org.apache.spark.sql.execution.joins.CartesianProductExec.doExecute(CartesianProductExec.scala:100)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:235)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:42)\n\tat org.apache.spark.sql.execution.BaseLimitExec$class.inputRDDs(limit.scala:62)\n\tat org.apache.spark.sql.execution.LocalLimitExec.inputRDDs(limit.scala:95)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:368)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange.prepareShuffleDependency(ShuffleExchange.scala:85)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange$$anonfun$doExecute$1.apply(ShuffleExchange.scala:121)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange$$anonfun$doExecute$1.apply(ShuffleExchange.scala:112)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange.doExecute(ShuffleExchange.scala:112)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:235)\n\tat org.apache.spark.sql.execution.BaseLimitExec$class.inputRDDs(limit.scala:62)\n\tat org.apache.spark.sql.execution.GlobalLimitExec.inputRDDs(limit.scala:105)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:141)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:141)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:368)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:133)\n\tat org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2371)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n\tat org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2765)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2370)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2377)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2113)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2112)\n\tat org.apache.spark.sql.Dataset.withTypedCallback(Dataset.scala:2795)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2112)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2327)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.zeppelin.spark.ZeppelinContext.showDF(ZeppelinContext.java:235)\n\tat org.apache.zeppelin.spark.SparkSqlInterpreter.interpret(SparkSqlInterpreter.java:130)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:97)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:498)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:175)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:139)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:748)\n"
          }
        ]
      },
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "country\tcount\nUS\t130\nCA\t32\nNL\t20\nIT\t6\nGB\t3\nJP\t1\nHK\t1\nCN\t1\n"
      },
      "apps": [],
      "jobName": "paragraph_1440282956044_-1934360175",
      "id": "20150822-223556_1799188434",
      "dateCreated": "Aug 22, 2015 10:35:56 PM",
      "dateStarted": "Sep 8, 2017 1:34:22 PM",
      "dateFinished": "Sep 8, 2017 1:34:24 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "user": "anonymous",
      "dateUpdated": "Sep 8, 2017 1:34:14 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "result": {
        "code": "SUCCESS",
        "type": "TEXT"
      },
      "apps": [],
      "jobName": "paragraph_1440376213626_2115030291",
      "id": "20150824-003013_225704440",
      "dateCreated": "Aug 24, 2015 12:30:13 AM",
      "dateStarted": "Aug 24, 2015 12:36:45 AM",
      "dateFinished": "Aug 24, 2015 12:36:46 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "AccessLog",
  "id": "2AYDJMVVQ",
  "angularObjects": {
    "2CSQVQNMY:shared_process": [],
    "2CUCNGYHD:shared_process": [],
    "2CTHCZ228:shared_process": [],
    "2CS7KURMR:shared_process": [],
    "2CTWJTA6U:shared_process": [],
    "2CUEYN5CF:shared_process": [],
    "2CSAE7DD1:shared_process": [],
    "2CSKYC6X3:shared_process": [],
    "2CUPXYA25:shared_process": [],
    "2CSUZP5VB:shared_process": [],
    "2CV4NAKFR:shared_process": [],
    "2CS5GENWP:shared_process": [],
    "2CVA4QZYS:shared_process": [],
    "2CTN1XAA8:shared_process": [],
    "2CS415K52:shared_process": [],
    "2CTKXG1NV:shared_process": [],
    "2CRN1EBQS:shared_process": [],
    "2CUVN5X2S:shared_process": [],
    "2CS1EK424:shared_process": []
  },
  "config": {},
  "info": {}
}